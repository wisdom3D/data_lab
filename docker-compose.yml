services:
  # ===============================
  # PostgreSQL + PostGIS
  # ===============================
  postgres:
    image: postgis/postgis:15-3.4
    container_name: postgres_postgis
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER}" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    restart: always

  # ===============================
  # pgAdmin (PostgreSQL UI)
  # ===============================
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    depends_on:
      - postgres
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    restart: always

  # ===============================
  # Redis (Airflow + Superset cache)
  # ===============================
  redis:
    image: redis:7
    container_name: airflow_redis
    ports:
      - "6379:6379"
    restart: always

  # ===============================
  # MinIO (Data Lake S3 compatible)
  # ===============================
  minio:
    image: minio/minio:latest
    container_name: minio_datalake
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    restart: always

  # ===============================
  # Apache Superset
  # ===============================
  superset:
    image: apache/superset:latest
    container_name: superset
    depends_on:
      - postgres
      - redis
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY}
    ports:
      - "8088:8088"
    volumes:
      - superset_home:/app/superset_home
    command: >
      bash -c " superset db upgrade && superset fab create-admin --username ${SUPERSET_ADMIN_USERNAME} --firstname Superset --lastname Admin --email admin@superset.com --password ${SUPERSET_ADMIN_PASSWORD} && superset init && superset run -h 0.0.0.0 -p 8088 "
    restart: always

  # ===============================
  # Airflow Init
  # ===============================
  airflow-init:
    build: .
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: ""
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW_UID: ${AIRFLOW_UID}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: postgres
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ingest:/opt/airflow/ingest
      - ./sql:/opt/airflow/sql
      - ./data:/opt/airflow/data
      - ./bad_records.log:/opt/airflow/bad_records.log
    command: >
      bash -c " airflow db migrate && airflow users create --username ${AIRFLOW_ADMIN_USERNAME} --firstname admin --lastname admin --role Admin --email ${AIRFLOW_ADMIN_EMAIL} --password ${AIRFLOW_ADMIN_PASSWORD} "

  # ===============================
  # Airflow Webserver
  # ===============================
  airflow-webserver:
    build: .
    container_name: airflow_webserver
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW_UID: ${AIRFLOW_UID}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: postgres
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ingest:/opt/airflow/ingest
      - ./sql:/opt/airflow/sql
      - ./data:/opt/airflow/data
      - ./bad_records.log:/opt/airflow/bad_records.log
    ports:
      - "8080:8080"
    command: webserver
    restart: always

  # ===============================
  # Airflow Scheduler
  # ===============================
  airflow-scheduler:
    build: .
    container_name: airflow_scheduler
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW_UID: ${AIRFLOW_UID}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: postgres
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ingest:/opt/airflow/ingest
      - ./sql:/opt/airflow/sql
      - ./data:/opt/airflow/data
      - ./bad_records.log:/opt/airflow/bad_records.log
    command: scheduler
    restart: always

  # ===============================
  # Airflow Worker (Celery)
  # ===============================
  airflow-worker:
    build: .
    container_name: airflow_worker
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW_UID: ${AIRFLOW_UID}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ingest:/opt/airflow/ingest
      - ./sql:/opt/airflow/sql
      - ./data:/opt/airflow/data
      - ./bad_records.log:/opt/airflow/bad_records.log
    command: celery worker
    restart: always

volumes:
  postgres_data:
  minio_data:
  pgadmin_data:
  superset_home:
